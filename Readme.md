# ğŸ› ï¸ Projeto de Pipeline Lakehouse com Apache Airflow e PySpark

Este repositÃ³rio contÃ©m um pipeline de dados desenvolvido com Apache Airflow e PySpark, estruturado com base nas camadas **Bronze**, **Silver** e **Gold** de um modelo Lakehouse.

## ğŸ“ Estrutura do Projeto

dags/
â”œâ”€â”€ json_to_bronze.py # DAG responsÃ¡vel por transformar arquivos JSON em Parquet (camada Bronze)
â”œâ”€â”€ data_to_silver.py # DAG que remove prefixos das colunas e gera a camada Silver
â”œâ”€â”€ processar_gold.py # DAG que gera os dados agregados para a camada Gold
â”œâ”€â”€ pipeline_lakehouse.py # DAG principal que orquestra todas as etapas do pipeline

## ğŸ—‚ï¸ Estrutura do Pipeline

â”œâ”€â”€ landing/                  # Dados brutos recebidos em formato JSON
â”‚ â””â”€â”€ arquivos_json/          # Subpastas com arquivos JSON por entidade
â”‚     â”œâ”€â”€ customers/
â”‚     â”œâ”€â”€ orders/
â”‚     â””â”€â”€ order_item/
â”‚
â”œâ”€â”€ bronze/                  # Dados convertidos de JSON para Parquet
â”‚   â”œâ”€â”€ customers/
â”‚   â”œâ”€â”€ orders/
â”‚   â””â”€â”€ order_item/
â”‚
â”œâ”€â”€ silver/                  # Dados tratados e limpos
â”‚   â”œâ”€â”€ customers/
â”‚   â”œâ”€â”€ orders/
â”‚   â””â”€â”€ order_item/
â”‚
â””â”€â”€ gold/                    # Dados prontos para consumo analÃ­tico
    â””â”€â”€ pedidos_por_cidade_estado/


## ğŸ”„ Pipeline de OrquestraÃ§Ã£o (`pipeline_lakehouse.py`)

A DAG principal `pipeline_lakehouse` executa as trÃªs etapas principais do fluxo:

1. **Camada Landing â†’ Bronze (`json_to_bronze_task`)**:  
   - LÃª arquivos JSON da camada *Landing*.
   - Converte para formato Parquet.
   - Salva os dados tratados na camada *Bronze*.

2. **Camada Bronze â†’ Silver (`data_to_silver_task`)**:  
   - LÃª os dados em Parquet da camada Bronze.
   - Remove prefixos das colunas e realiza transformaÃ§Ãµes.
   - Salva os dados tratados na camada *Silver*.

3. **Camada Silver â†’ Gold (`processar_gold_task`)**:  
   - Realiza junÃ§Ãµes e agregaÃ§Ãµes nos dados da Silver.
   - Salva os resultados analÃ­ticos na camada *Gold*.

> As tarefas de Bronze e Silver sÃ£o executadas **em paralelo**, e a camada Gold sÃ³ Ã© processada apÃ³s ambas serem concluÃ­das.

## â–¶ï¸ ExecuÃ§Ã£o

### PrÃ©-requisitos

- Apache Airflow instalado e configurado.
- PySpark disponÃ­vel no ambiente.
- Estrutura de diretÃ³rios criada:

/home/bru_silveira/airflow/lakehouse/
â”œâ”€â”€ landing/
â”œâ”€â”€ bronze/
â”œâ”€â”€ silver/
â””â”€â”€ gold/

### Ativando o Airflow

```bash
# Inicialize o Airflow
airflow db init
airflow scheduler
airflow webserver --port 8080
```

Acesse a interface: http://localhost:8080

### Visualizando o Pipeline

Na UI do Airflow, vocÃª verÃ¡ as DAGs:

- json_to_bronze

- data_to_silver

- processar_gold

- pipeline_lakehouse âœ… (orquestradora principal)

VocÃª pode ativar e rodar qualquer uma separadamente, ou a pipeline_lakehouse para executar o pipeline completo.

### ğŸ‘©â€ğŸ’» Autoria
Desenvolvido por Bruna Silveira
